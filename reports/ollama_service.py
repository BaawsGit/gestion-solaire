import requests
import json
from django.conf import settings
from datetime import datetime, timedelta
from django.utils import timezone
from interventions.models import Intervention
from django.db.models import Count, Avg, Q


class OllamaService:
    """Service pour interagir avec l'API Ollama"""

    def __init__(self, base_url="http://localhost:11434"):
        self.base_url = base_url
        self.model_name = "gemma3:4b"  # ou "gemma3:4b" selon votre configuration

    def check_connection(self):
        """V√©rifie si Ollama est accessible et quels mod√®les sont disponibles"""
        try:
            # Essayer d'acc√©der √† l'API
            response = requests.get(f"{self.base_url}/api/tags", timeout=20)
            if response.status_code == 200:
                models = response.json().get("models", [])
                available_models = [model.get("name") for model in models]

                # V√©rifier si notre mod√®le est disponible
                model_available = any(self.model_name in name for name in available_models)

                return {
                    'success': True,
                    'available': True,
                    'message': "Ollama est connect√©",
                    'models': available_models,
                    'model_available': model_available,
                    'url': self.base_url,
                    'model': self.model_name
                }
            else:
                return {
                    'success': False,
                    'available': False,
                    'message': f"Erreur API Ollama: {response.status_code}"
                }

        except requests.exceptions.ConnectionError:
            return {
                'success': False,
                'available': False,
                'message': "Impossible de se connecter √† Ollama"
            }
        except requests.exceptions.Timeout:
            return {
                'success': False,
                'available': False,
                'message': "Timeout: Ollama ne r√©pond pas"
            }
        except Exception as e:
            return {
                'success': False,
                'available': False,
                'message': f"Erreur inattendue: {str(e)}"
            }

    def test_model(self):
        """Teste si le mod√®le peut g√©n√©rer une r√©ponse simple"""
        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": "Bonjour, peux-tu me dire 'OK' en une seule ligne?",
                    "stream": False,
                    "options": {"temperature": 0.1}
                },
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                return {
                    'success': True,
                    'message': "Mod√®le fonctionnel",
                    'response': result.get('response', '')
                }
            else:
                return {
                    'success': False,
                    'message': f"Erreur lors du test du mod√®le: {response.status_code}"
                }

        except Exception as e:
            return {
                'success': False,
                'message': f"Erreur lors du test: {str(e)}"
            }

    def generate_report_analysis(self, month, year, stats):
        """G√©n√®re une analyse IA bas√©e sur les donn√©es fournies"""
        try:
            # Pr√©parer le prompt avec le contexte
            prompt = self._create_report_prompt(month, year, stats)

            print(f"üîç Envoi du prompt √† Ollama ({len(prompt)} caract√®res)...")

            # Appeler l'API Ollama
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 800,  # R√©duire la longueur de r√©ponse
                        "num_ctx": 2048  # R√©duire le contexte
                    }
                },
                timeout=180
            )

            print("‚úÖ R√©ponse re√ßue d'Ollama")

            if response.status_code == 200:
                result = response.json()
                analysis = result.get('response', '')

                # Nettoyer et structurer la r√©ponse
                return self._parse_ai_response(analysis, stats)
            else:
                return {
                    'success': False,
                    'error': f"Erreur API Ollama: {response.status_code}",
                    'analysis': "Impossible de g√©n√©rer l'analyse IA."
                }


        except requests.exceptions.Timeout:
            print("‚è∞ Timeout Ollama - La r√©ponse prend trop de temps")
            return {
                'success': False,
                'error': "Ollama met trop de temps √† r√©pondre. Essayez avec un mod√®le plus l√©ger ou r√©duisez la p√©riode d'analyse.",
                'analysis': "Timeout lors de la g√©n√©ration de l'analyse."
            }

        except Exception as e:
            print(f"‚ùå Erreur Ollama: {e}")
            return {
                'success': False,
                'error': str(e),
                'analysis': "Erreur lors de la g√©n√©ration de l'analyse."
            }

    def _create_report_prompt(self, month, year, stats):
        """Cr√©e le prompt pour l'analyse du rapport"""

        # Formater le mois
        from datetime import datetime
        month_name = datetime.strptime(str(month), "%m").strftime("%B")

        prompt = f"""Tu es un analyste expert en maintenance solaire. Analyse ces donn√©es du mois de {month_name} {year} et fournis un rapport structur√©.

    ## STATISTIQUES DU MOIS:
    - P√©riode: {month_name} {year}
    - Total interventions: {stats.get('total_interventions', 0)}
    - Interventions termin√©es: {stats.get('completed_interventions', 0)}
    - Interventions en cours: {stats.get('ongoing_interventions', 0)}
    - Taux de r√©ussite: {stats.get('success_rate', 0):.1f}%
    - Indice de performance interne (bas√© sur le taux de r√©ussite): {stats.get('performance_score', 0):.1f}/10
    - Dur√©e moyenne: {stats.get('avg_duration', 'N/A')}
    - Chiffre d'affaires total: {stats.get('total_revenue', 0):,.0f} FCFA

    ## IMPORTANT:
    - L'indice de performance est un indicateur INTERNE de l'entreprise, calcul√© √† partir du taux de r√©ussite
    - Ce n'est PAS un score de satisfaction client
    - Il mesure l'efficacit√© op√©rationnelle de l'entreprise

    ## R√âPARTITION PAR TYPE:
    {self._format_type_stats(stats.get('interventions_by_type', []))}

    ## PERFORMANCE DES TECHNICIENS:
    {self._format_technician_stats(stats.get('top_technicians', []))}

    ## T√ÇCHE:
    G√©n√®re un rapport d'analyse complet avec les sections suivantes:

    1. **R√âSUM√â EX√âCUTIF** (2-3 phrases maximum)
    2. **RECOMMANDATIONS CL√âS** (liste num√©rot√©e de 1-3 recommandations concr√®tes)
    3. **ANALYSE TECHNIQUE** (analyse d√©taill√©e des pannes, pi√®ces remplac√©es, tendances)
    4. **MAINTENANCE PR√âDICTIVE** (pr√©dictions pour les mois √† venir bas√©es sur les donn√©es)

    Ton: Professionnel, factuel, constructif.
    Format: Utilise des balises HTML simples <p>, <ul>, <li>, <strong>, <em>.
    Ne mets pas de code markdown (```), utilise uniquement du HTML."""

        return prompt

    def _format_type_stats(self, type_stats):
        """Formate les statistiques par type"""
        if not type_stats:
            return "Aucune donn√©e"

        lines = []
        for item in type_stats:
            lines.append(f"- {item['type_intervention']}: {item['count']} interventions")
        return "\n".join(lines)

    def _format_technician_stats(self, tech_stats):
        """Formate les statistiques des techniciens"""
        if not tech_stats:
            return "Aucune donn√©e"

        lines = []
        for item in tech_stats:
            lines.append(f"- {item['technicien__nom']}: {item['intervention_count']} interventions")
        return "\n".join(lines)

    def _parse_ai_response(self, response, stats):
        """Nettoie et structure la r√©ponse de l'IA"""
        # Retirer les √©ventuels marqueurs de code
        response = response.replace("```html", "").replace("```", "").strip()

        # S√©parer les sections
        sections = {
            'summary': '',
            'recommendations': '',
            'technical_analysis': '',
            'predictive_maintenance': ''
        }

        # Simple parsing par sections (am√©liorable)
        lines = response.split('\n')
        current_section = None

        for line in lines:
            line_lower = line.lower()
            if 'r√©sum√©' in line_lower or 'executif' in line_lower:
                current_section = 'summary'
            elif 'recommandation' in line_lower:
                current_section = 'recommendations'
            elif 'technique' in line_lower:
                current_section = 'technical_analysis'
            elif 'pr√©dictive' in line_lower:
                current_section = 'predictive_maintenance'

            if current_section and line.strip():
                sections[current_section] += line + '\n'

        # Si le parsing a √©chou√©, mettre tout dans le r√©sum√©
        if not any(sections.values()):
            sections['summary'] = response

        return {
            'success': True,
            'sections': sections,
            'raw_response': response,
            'timestamp': datetime.now().isoformat()
        }